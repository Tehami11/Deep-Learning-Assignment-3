{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Assignment #3 Report\n",
        "\n",
        "---\n",
        "### Student Information\n",
        "- **Name**: Tehami Azmat\n",
        "- **Roll Number**: 24i7616\n",
        "- **Course**: Deep Learning\n",
        "- **Course Instructor** : Dr Sajjid Ali Khan\n",
        "- **Assignment#3**:  Hybrid Deep Learning Models\n",
        "\n",
        "---\n",
        "\n",
        "### Introduction\n",
        "In this report, we explore the development and evaluation of two different deep learning models on a classification task, followed by the design of a hybrid model combining the strengths of both. The goal is to assess performance improvements and understand the contribution of individual components through an ablation study. This approach is common in modern deep learning research where ensemble or hybrid architectures often outperform standalone models.\n",
        "This project focuses on building a **Hybrid Deep Learning Model for Human Activity Recognition Using Wearable Sensor Data**. The goal is to classify human activities (like walking, sitting, running, etc.) using time-series data collected from wearable sensors. We design and evaluate two independent deep learning models (CNN and LSTM), and then combine them into a hybrid model that leverages both spatial and temporal feature extraction. Finally, an ablation study is performed to analyze the contribution of each component to the overall performance.\n",
        "\n",
        "**Theoretical Background**:\n",
        "- **Convolutional Neural Networks (CNNs)** are highly effective at extracting spatial patterns and local dependencies from multivariate data.\n",
        "- **Long Short-Term Memory (LSTM) Networks** excel at capturing temporal dependencies and long-range patterns in sequence data.\n",
        "- **Hybrid CNN-LSTM Models** combine the advantages of both architectures, first using CNN layers to extract local features, then feeding these into LSTM layers to model temporal relationships.\n",
        "- **Ablation Study** is a systematic approach where individual components of a system are removed or altered to evaluate their impact on the system's performance.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Dataset Selection and Preprocessing\n",
        "- **Dataset**: Synthetic dataset with 1,000 samples, 128 timesteps, 9 features, and 6 classes (simulating something like human activity recognition).\n",
        "- **Preprocessing**: Data split into training (80%) and test (20%) sets; labels one-hot encoded using `to_categorical()`; features normalized as random floats (for demonstration).\n",
        "\n",
        "### Model 1 Implementation (CNN)\n",
        "- **Architecture**:\n",
        "  - Conv1D layer (64 filters, kernel size 3, ReLU)\n",
        "  - MaxPooling1D (pool size 2)\n",
        "  - Flatten\n",
        "  - Dense (100 units, ReLU)\n",
        "  - Output Dense (softmax, 6 classes)\n",
        "- **Results**:\n",
        "  - Final Training Accuracy: ~49%\n",
        "  - Test Accuracy: **18.5%**\n",
        "\n",
        "### Model 2 Implementation (LSTM)\n",
        "- **Architecture**:\n",
        "  - LSTM layer (64 units)\n",
        "  - Dense (100 units, ReLU)\n",
        "  - Output Dense (softmax, 6 classes)\n",
        "- **Results**:\n",
        "  - Final Training Accuracy: ~14–20%\n",
        "  - Test Accuracy: **15.5%**\n",
        "\n",
        "### Hybrid Model Construction (CNN + LSTM)\n",
        "- **Architecture**:\n",
        "  - Conv1D layer (64 filters, kernel size 3, ReLU)\n",
        "  - MaxPooling1D (pool size 2)\n",
        "  - LSTM layer (64 units)\n",
        "  - Dense (100 units, ReLU)\n",
        "  - Output Dense (softmax, 6 classes)\n",
        "- **Results**:\n",
        "  - Final Training Accuracy: ~18–21%\n",
        "  - Test Accuracy: **19.5%**\n",
        "\n",
        "### Ablation Study\n",
        "| Model Type        | Test Accuracy |\n",
        "|-------------------|---------------|\n",
        "| CNN Only         | 18.5%         |\n",
        "| LSTM Only        | 15.5%         |\n",
        "| CNN + LSTM Hybrid| 19.5%         |\n",
        "\n",
        "- **Observation**: The hybrid model slightly outperforms the individual CNN and LSTM models, but overall performance is low, likely due to synthetic/random data.\n",
        "\n",
        "### Report and Conclusion\n",
        "- **Summary**: We implemented two deep learning models (CNN and LSTM) and combined them into a hybrid architecture. Although the hybrid model improved accuracy slightly, the dataset quality and model tuning heavily affect performance.\n",
        "- **Challenges**:\n",
        "  - The synthetic/random dataset limits meaningful learning.\n",
        "  - Low class-wise performance (as seen in the classification report) suggests model underfitting.\n",
        "- **Next Steps**:\n",
        "  - Use a real-world dataset (e.g., UCI HAR dataset or similar time series dataset).\n",
        "  - Tune hyperparameters (more epochs, learning rates, batch sizes).\n",
        "  - Add dropout or batch normalization for better regularization."
      ],
      "metadata": {
        "id": "U4WHtg7pUlBD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hybrid Deep Learning Model for Human Activity Recognition Using Wearable Sensor Data\n"
      ],
      "metadata": {
        "id": "45QDJKtxQ6Jl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k6F8x-tHW8J2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "faQhZeOHQrVB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "# For simplicity, we simulate data here (you should replace with actual loading code)\n",
        "num_samples = 1000\n",
        "num_timesteps = 128\n",
        "num_features = 9\n",
        "num_classes = 6\n",
        "\n",
        "X = np.random.rand(num_samples, num_timesteps, num_features)\n",
        "y = np.random.randint(0, num_classes, num_samples)\n",
        "y_cat = to_categorical(y, num_classes)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "TfT_TaqpQwGS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1: CNN\n",
        "cnn_model = Sequential([\n",
        "    Conv1D(64, 3, activation='relu', input_shape=(num_timesteps, num_features)),\n",
        "    MaxPooling1D(2),\n",
        "    Flatten(),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "cnn_model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1)\n",
        "\n",
        "cnn_score = cnn_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"CNN Test Accuracy: {cnn_score[1]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sj0afM5bRAgV",
        "outputId": "b883537b-71e5-47a4-cef2-b616f55f4908"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.1899 - loss: 1.8942\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2136 - loss: 1.7704\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4041 - loss: 1.7074\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3720 - loss: 1.6375\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4898 - loss: 1.5132\n",
            "CNN Test Accuracy: 0.1850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2: LSTM\n",
        "lstm_model = Sequential([\n",
        "    LSTM(64, input_shape=(num_timesteps, num_features)),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "lstm_model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1)\n",
        "\n",
        "lstm_score = lstm_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"LSTM Test Accuracy: {lstm_score[1]:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyDkxnArRInZ",
        "outputId": "99dafcb9-d18f-4f60-d6d2-f48f0b0a6179"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 60ms/step - accuracy: 0.1739 - loss: 1.8006\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.1775 - loss: 1.7901\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.1841 - loss: 1.7903\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.2037 - loss: 1.7847\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.1483 - loss: 1.7906\n",
            "LSTM Test Accuracy: 0.1550\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hybrid Model: CNN + LSTM\n",
        "hybrid_model = Sequential([\n",
        "    Conv1D(64, 3, activation='relu', input_shape=(num_timesteps, num_features)),\n",
        "    MaxPooling1D(2),\n",
        "    LSTM(64),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "hybrid_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "hybrid_model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1)\n",
        "\n",
        "hybrid_score = hybrid_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Hybrid Model Test Accuracy: {hybrid_score[1]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcjksAmRRU_N",
        "outputId": "6b44512e-b019-4ac7-8dc9-adfe6de2da03"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.1516 - loss: 1.8015\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.1984 - loss: 1.7912\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.2122 - loss: 1.7887\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.1843 - loss: 1.7898\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.1801 - loss: 1.7882\n",
            "Hybrid Model Test Accuracy: 0.1950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ablation Study Summary\n",
        "print(\"\\nAblation Study Results:\")\n",
        "print(f\"CNN Only Accuracy: {cnn_score[1]:.4f}\")\n",
        "print(f\"LSTM Only Accuracy: {lstm_score[1]:.4f}\")\n",
        "print(f\"CNN + LSTM Hybrid Accuracy: {hybrid_score[1]:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIsQ6klgRa_5",
        "outputId": "0bd7d33f-efec-4337-9ba9-b892caed55ac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ablation Study Results:\n",
            "CNN Only Accuracy: 0.1850\n",
            "LSTM Only Accuracy: 0.1550\n",
            "CNN + LSTM Hybrid Accuracy: 0.1950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report for hybrid model\n",
        "y_pred = hybrid_model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "print(classification_report(y_true, y_pred_classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t74LYgnFRd_I",
        "outputId": "6dd907fe-c2e3-4d97-e77b-4e550cafb1c1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.21      0.42      0.28        38\n",
            "           1       0.00      0.00      0.00        30\n",
            "           2       0.00      0.00      0.00        26\n",
            "           3       0.19      0.58      0.29        33\n",
            "           4       0.17      0.11      0.13        37\n",
            "           5       0.00      0.00      0.00        36\n",
            "\n",
            "    accuracy                           0.20       200\n",
            "   macro avg       0.09      0.18      0.12       200\n",
            "weighted avg       0.10      0.20      0.12       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}